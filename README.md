WebNavigatorAgent â€“ Hackathon Project:
An AI-powered autonomous web navigation agent built during the ByteXL Hackathon.
This project demonstrates how LLMs, memory, and browser automation can work together to explore and interact with the web intelligently.

Features:
LLM-powered reasoning â€“ Uses a language model to decide actions.
Browser automation â€“ Automatically opens sites, searches, and interacts with elements.
Memory system â€“ Stores visited pages, actions, and results.
Modular agent design â€“ Each component (LLM, Tools, Memory) can be extended independently.

Tech Stack:
Python 3.12+
Selenium / BrowserTools (for web automation)
Ollama (for the web automation search and analyse the informations)
Custom Agent Core (coordinates LLM + browser + memory)

Project Structure:
HACHATHON FOR BYTEXL/
â”‚â”€â”€ agent/
â”‚   â”œâ”€â”€ Advacanced_Agent.py
â”‚   â”œâ”€â”€ Agent_core.py
â”‚   â””â”€â”€ __pycache__/
â”‚
â”‚â”€â”€ LLM/
â”‚   â”œâ”€â”€ llm_handler.py
â”‚   â””â”€â”€ __pycache__/
â”‚
â”‚â”€â”€ Memory/
â”‚   â”œâ”€â”€ Memory.py
â”‚   â””â”€â”€ __pycache__/
â”‚
â”‚â”€â”€ Tools/
â”‚   â”œâ”€â”€ Browser_Tools.py
â”‚   â””â”€â”€ __pycache__/
â”‚
â”‚â”€â”€ main.py
â”‚â”€â”€ requirements_db.txt
â”‚â”€â”€ Runnable2.py
â”‚â”€â”€ __pycache__/


Getting Started:
(Befor getting started install Ollama and then Download the any model and then change the model name in the llm handler file)
âš™ï¸ Installing Ollama

Ollama lets you run LLMs locally on your system.

1ï¸âƒ£ Install Ollama

Download and install Ollama from the official site:
ğŸ‘‰ https://ollama.com/download

Windows: Download the installer and follow setup steps.
macOS: Install via .dmg or using Homebrew:
brew install ollama

Linux:
curl -fsSL https://ollama.com/install.sh | sh
2ï¸âƒ£ Verify installation
Run this command in your terminal:
ollama --version
3ï¸âƒ£ Pull a model
For example, to pull Llama 3.1:
```
ollama pull llama3.1
```
4ï¸âƒ£ Run a quick test
```
ollama run llama3.1
```
5ï¸âƒ£ Using Ollama in Python
You can interact with Ollama models using the Python client:
```
pip install ollama

ollama pull (model_name)
```
Example:
import ollama
response = ollama.chat(model="llama3.1", messages=[
    {"role": "user", "content": "Hello, what can you do?"}
])
print(response['message']['content'])


create the virtual environmet and then download the dependencies

if not worked:
change the environment variables and try in vscode or if can change the path in the vscode 

1ï¸. Clone the repository
```
git clone https://github.com/SP-Niranjan/web_navigatior_AI_Agent

cd the folder ex: cd web_navigator_AI_Agent
```
2ï¸. Install dependencies:
```
pip install -r requirements.txt
```
3ï¸. Run the project:
```
python Runnable2.py
```
Example Use Case:
Search for "Show me Shoe within 500-10000"

 The agent will search the browser backend, search automatically, and store actions in memory, extract the information and ollama will analyse the informations then give the best suiting output.
